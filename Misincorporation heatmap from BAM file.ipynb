{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44ba7ab",
   "metadata": {},
   "source": [
    "# Plot misincorporation heatmaps from BAM files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408d436",
   "metadata": {},
   "source": [
    "This short pipeline makes pileups from BAM files, extract the pileups in sequences of interest, and build misincorporation heatmaps as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2315d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following script saved as parse_pileups.py\n",
    "# Dependency of pileup_analysis.sh\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "infile = open(sys.argv[1], 'rt')\n",
    "infile.readline()\n",
    "outfile = open(sys.argv[2], 'w+')\n",
    "\n",
    "# List sequences of interests ID from custom reference\n",
    "seq_of_interest = ['ID1','ID2','ID3']\n",
    "\n",
    "# Extract relevant information (Depth, Allele Freqs) from pileup files for sequences of interest only\n",
    "for line in infile:\n",
    "    if line[0] != '#':\n",
    "        array = line.strip().split('\\t')\n",
    "        ID, position, ref, alt, INFO = array[0], array[1], array[3], array[4], array[7]\n",
    "\n",
    "        if ID in seq_of_interest:\n",
    "            alt = alt.split(',')\n",
    "            x = re.search(\"DP=([0-9]+);AD=([0-9,\\,]+)\", INFO)\n",
    "            DP, AD = x.group(1), x.group(2)\n",
    "            AD = AD.split(',')\n",
    "\n",
    "            outfile.write(ID+'\\t'+position+'\\t'+DP+'\\t'+ref+'\\t'+str(float(AD[0])/float(DP))+'\\t')\n",
    "            \n",
    "            for i in range(0, len(alt)):\n",
    "                outfile.write(alt[i]+'\\t'+str(float(AD[i+1])/float(DP))+'\\t')\n",
    "\n",
    "            outfile.write('\\n')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Following script saved as pileup_analysis.sh\n",
    "# Command: sbatch pileup_analysis.sh experiment\n",
    "# Create the pileups and filter output for sequences of interest\n",
    "\n",
    "###################################################################################################################\n",
    "#! /bin/bash\n",
    "\n",
    "#SBATCH --job-name wil_works\n",
    "#SBATCH --ntasks=4\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --partition=ccr\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --gres=lscratch:500 \n",
    "#SBATCH --mem=50g\n",
    "\n",
    "experiment=$1\n",
    "\n",
    "# Make pileups\n",
    "module load samtools\n",
    "for file in ${experiment}.splitFastq/*.sorted.bam ; do bcftools mpileup -d 1000000000  ${file} -f custom_reference.fa -a INFO/AD > ${file}.pileup; done\n",
    "\n",
    "# Keep only sequences of interest\n",
    "for file in ${experiment}.splitFastq/*.pileup ; do python3 parse_pileups.py ${file} ${file}.out ; done\n",
    "\n",
    "# Rename files\n",
    "for file in ${experiment}.splitFastq/*.pileup.out ; do mv \"${file}\" \"`echo ${file} | sed 's/.sorted.bam//'`\"; done\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run previous pipeline\n",
    "sbatch pileup_analysis.sh experiment_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_pileups.py\n",
    "# gather all pileups in one table - useful for publication\n",
    "# https://www.geeksforgeeks.org/how-to-read-multiple-text-files-from-folder-in-python/\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Folder Path \n",
    "path = sys.argv[1]\n",
    "\n",
    "# Change the directory \n",
    "os.chdir(path) \n",
    "\n",
    "all_rows = {}\n",
    "\n",
    "# Read text files\n",
    "def read_text_file(file_path): \n",
    "    with open(file_path, 'r') as f: \n",
    "\n",
    "        rows = {}\n",
    "        \n",
    "        for line in f:\n",
    "            \n",
    "            array = line.strip().split('\\t')\n",
    "            ID = array[0]+'|'+array[1]\n",
    "            DP = array[2]\n",
    "\n",
    "            variants = ''\n",
    "            \n",
    "            for field in array[3:]:\n",
    "                if field != '<*>':\n",
    "                    variants = variants+field+','\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if ID not in rows:\n",
    "                rows[ID] = ''\n",
    "\n",
    "            rows[ID] = rows[ID] + 'DP='+DP+','+ variants\n",
    "            \n",
    "    return(rows)\n",
    "\n",
    "                \n",
    "# iterate through all files\n",
    "for file in os.listdir(): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\"pileup.out\"):\n",
    "    \n",
    "        column = file.replace(\".pileup.out\", \"\")\n",
    "\n",
    "        file_path = f\"{path}{file}\"\n",
    "  \n",
    "        # call read text file function \n",
    "        all_rows[column] =  read_text_file(file_path)\n",
    "\n",
    "        \n",
    "final_rows = {}\n",
    "\n",
    "columns = []\n",
    "for column in all_rows:\n",
    "    columns.append(column)\n",
    "    \n",
    "    for row in all_rows[column]:\n",
    "        if row not in final_rows:\n",
    "            final_rows[row] = []\n",
    "            \n",
    "        final_rows[row].append(all_rows[column][row])\n",
    "        \n",
    "df = pd.DataFrame.from_dict(final_rows, orient='index', columns=columns)\n",
    "df.to_csv('pileup_summary.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136834c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run previous script\n",
    "cd experiment_dir\n",
    "python3 summarize_pileups.py ./\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misincorporation_heatmap.py\n",
    "# prepare input for heatmap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "translate = {'ID1' : 'SEQUENCE_1', 'ID2' : 'SEQUENCE_2', 'ID3' : 'SEQUENCE_3'}\n",
    "\n",
    "infile = pd.read_csv('pileup_summary.csv')\n",
    "\n",
    "ID_POS = infile.iloc[:, 0]\n",
    "\n",
    "experiment = sys.argv[1]\n",
    "\n",
    "# extract 3 replicates of the same experiment \n",
    "Rep1 = infile[experiment+'_rep1']\n",
    "Rep2 = infile[experiment+'_rep2']\n",
    "Rep3 = infile[experiment+'_rep3']\n",
    "\n",
    "dic_depths = {}\n",
    "dic = {}\n",
    "\n",
    "# Compute freq of incorporations matching the reference\n",
    "# Also returns read depth\n",
    "for i in range(0, len(ID_POS)):\n",
    "    \n",
    "    ID, POS = ID_POS[i].split('|')\n",
    "    \n",
    "    DP_depths = []\n",
    "    DP_refs = []\n",
    "    \n",
    "    for Rep in [Rep1, Rep2, Rep3]:\n",
    "        \n",
    "        if 'nan' in str(Rep[i]):\n",
    "            \n",
    "            DP_depths.append(np.nan)\n",
    "            DP_refs.append(np.nan)\n",
    "                \n",
    "        else:\n",
    "            DP = Rep[i].split(',')[0].split('=')[1]\n",
    "            \n",
    "            DP_ref = Rep[i].split(',')[2]\n",
    "\n",
    "            if int(DP) > 1:\n",
    "                DP_refs.append(float(DP_ref))\n",
    "                DP_depths.append(int(DP))\n",
    "            else:\n",
    "                DP_refs.append(np.nan)  \n",
    "                DP_depths.append(np.nan)\n",
    "    \n",
    "    DP_ref_mean = np.nanmean(DP_refs)\n",
    "    \n",
    "    ID = translate[ID]\n",
    "    \n",
    "    if ID not in dic:\n",
    "        dic_depths[ID] = []\n",
    "        dic[ID] = []\n",
    "        \n",
    "    dic_depths[ID].append(DP_depths)\n",
    "    dic[ID].append(DP_ref_mean)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame.from_dict(dic, orient='index')\n",
    "df.to_csv(experiment+'_HeatMap.csv')\n",
    "\n",
    "df_depths = pd.DataFrame.from_dict(dic_depths, orient='index')\n",
    "df_depths.to_csv(experiment+'_HeatMap_depths.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run previous scripts for 3 different conditions\n",
    "for experiment in Condition_1 Condition_2 Condition_3 ; do python3 misincorporation_heatmap.py ${experiment} ; done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d989340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# https://www.r-bloggers.com/2015/09/passing-arguments-to-an-r-script-from-command-lines/\n",
    "# heatmap.R\n",
    "# Plot heatmap\n",
    "\n",
    "library(ggplot2)\n",
    "library(heatmaply)\n",
    "library(plotly)\n",
    "library(orca)\n",
    "\n",
    "\n",
    "args = commandArgs(trailingOnly=TRUE)\n",
    "\n",
    "\n",
    "# test if there is at least one argument: if not, return an error\n",
    "if (length(args)==0) {\n",
    "  stop(\"At least one argument must be supplied (input file).n\", call.=FALSE)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data <- read.csv(args[1], header=TRUE)\n",
    "data <- cbind(data[,1], data[,2:76])\n",
    "colnames(data) <- c('ID', seq(1,length(data[1,])-1))\n",
    "\n",
    "toplot <- data[-1]\n",
    "rownames(toplot) <- data$ID\n",
    "toplot <- toplot[order(rownames(toplot)), ]\n",
    "\n",
    "\n",
    "p <- heatmaply(toplot, \n",
    "        dendrogram = \"none\",\n",
    "        file = paste0(args[1],'.pdf'),\n",
    "        #plot_method = \"plotly\",\n",
    "        xlab = \"\", ylab = \"\", \n",
    "        main = args[1],\n",
    "        #scale = \"row\",\n",
    "        margins = c(60,100,40,20),\n",
    "        grid_color = \"white\",\n",
    "        grid_width = 0.00001,\n",
    "        titleX = FALSE,\n",
    "        hide_colorbar = TRUE,\n",
    "        branches_lwd = 0.1,\n",
    "        fontsize_row = 5, fontsize_col = 5,\n",
    "        labRow = rownames(toplot),\n",
    "        column_text_angle = 90,\n",
    "        )\n",
    "#############################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for experiment in Condition_1 Condition_2 Condition_3 ; do Rscript heatmap.R ${experiment}_HeatMap.csv ; done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
